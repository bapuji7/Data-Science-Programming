{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36cca93b",
   "metadata": {},
   "source": [
    "# WE03\n",
    "# Bapuji Satyala \n",
    "# U61600601"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f7467",
   "metadata": {},
   "source": [
    "In this Notebook we are generating a synthetic dataset which has two features and one target where we look at the data and do preprocessing if possible and save it to a csv file and this csv file will be further used in another notebook where we  use the data set for fitting it to the  Support vector Classification(SVC) by implementing the Hyper Parameter tuning.\n",
    "\n",
    "We are trying to predict if there will be crop yield or not by considering the Temperature and Humidity as the factors that are influencing the crop yield which is a case of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d4025",
   "metadata": {},
   "source": [
    "# Importing the required libraries that we will be using in this note book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cc2db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "np.random.seed(1)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import fbeta_score,make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d61d232",
   "metadata": {},
   "source": [
    "### Step 1: Generation of data set and storing it into data frame df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "723d7385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'TEMPERATURES_DEVIATION': np.random.randint(low=0,high=30,size=1000)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae85b0",
   "metadata": {},
   "source": [
    "I have generated the synthetic data of Temperature deviations where the minimum temperature deviation is 0 and the Maximum temperatire deviation of 30  by using the np.random.randint to generate random integers  and storing them in the column TEMPERATURES_DEVIATION of the data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d77b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SOIL_MOISTURE'] = pd.DataFrame({'SOIL_MOISTURE': np.random.randint(low=0,high=100,size=1000).round().astype(int)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7912d7",
   "metadata": {},
   "source": [
    "I have generated the synthetic data of Soil Moisture Percentages  where the minimum Soil Moisture Percentages  is 0 and the Maximum temperatire deviation of 100 by using the np.random.randint to generate random integers and storing them in the column SOIL_MOISTURE of the data frame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f4952",
   "metadata": {},
   "source": [
    "Now we are looking at the top 5 observations of the dataframe which contain the dat aof Soil Moisture and the temperture difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2507ea7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMPERATURES_DEVIATION</th>\n",
       "      <th>SOIL_MOISTURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEMPERATURES_DEVIATION  SOIL_MOISTURE\n",
       "0                       5             33\n",
       "1                      11             72\n",
       "2                      12             68\n",
       "3                       8             39\n",
       "4                       9             32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91824068",
   "metadata": {},
   "source": [
    "Here we are creating a new column CROP_YIELD based on the condition that the Values in the data frame of the column TEMPERATURES_DEVIATION is lesser than 15 and also the SOIL_MOISTURE percentage should be greater than 50 then we are considering it as yield and considering it as 1 if the condition fails we are considering as no yield and assigning 0 which is a boolean condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb28655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CROP_YIELD'] = ((df['TEMPERATURES_DEVIATION'] <15) & (df['SOIL_MOISTURE'] > 50)).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a3b039",
   "metadata": {},
   "source": [
    "Now we are looking at the top 5 observations of the dataframe which contain the data of Soil Moisture and the temperture difference along with the CROP_YIELD information as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90686503",
   "metadata": {},
   "source": [
    "### Step 2: Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f747d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMPERATURES_DEVIATION</th>\n",
       "      <th>SOIL_MOISTURE</th>\n",
       "      <th>CROP_YIELD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEMPERATURES_DEVIATION  SOIL_MOISTURE  CROP_YIELD\n",
       "0                       5             33           0\n",
       "1                      11             72           1\n",
       "2                      12             68           1\n",
       "3                       8             39           0\n",
       "4                       9             32           0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b84bd",
   "metadata": {},
   "source": [
    "We are looking at the number of rows and columns in the data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ee2646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa18805",
   "metadata": {},
   "source": [
    "Checking if there are any null values in the data frame and additing them to get more clear understanding on data if there are any nulls in the data frame or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e7c15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEMPERATURES_DEVIATION    0\n",
       "SOIL_MOISTURE             0\n",
       "CROP_YIELD                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c142839a",
   "metadata": {},
   "source": [
    "We are looking at the statstics of the data in the dataframe, from the below we can see the minimum values, maximum values and the mean and standard deviadtion in each column of the data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2161a574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMPERATURES_DEVIATION</th>\n",
       "      <th>SOIL_MOISTURE</th>\n",
       "      <th>CROP_YIELD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.421000</td>\n",
       "      <td>50.655000</td>\n",
       "      <td>0.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.767476</td>\n",
       "      <td>28.536403</td>\n",
       "      <td>0.444182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TEMPERATURES_DEVIATION  SOIL_MOISTURE   CROP_YIELD\n",
       "count             1000.000000    1000.000000  1000.000000\n",
       "mean                14.421000      50.655000     0.270000\n",
       "std                  8.767476      28.536403     0.444182\n",
       "min                  0.000000       0.000000     0.000000\n",
       "25%                  7.000000      26.000000     0.000000\n",
       "50%                 14.000000      52.000000     0.000000\n",
       "75%                 22.000000      76.000000     1.000000\n",
       "max                 29.000000      99.000000     1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e251fe9a",
   "metadata": {},
   "source": [
    "Here we are checking if the generated dataset is balanced or not where Value_cpunts() will give the unique values in the CROP_YIELD column of the dataframe. we are only concerened about the CROP_YIELD as it it will be Target Column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1e91c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    730\n",
       "1    270\n",
       "Name: CROP_YIELD, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CROP_YIELD'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3961f60f",
   "metadata": {},
   "source": [
    "We can see that 730 observations are 0 which is no yield and 270 which is yield."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8be486",
   "metadata": {},
   "source": [
    "### Step 3: Splitting the data into Train set and the Test set where our target column is sti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efadf64",
   "metadata": {},
   "source": [
    "We are assigning the features to X dataframe by dropping the column CROP_YIELD and assigning the target CROP_YIELD to Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4974ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('CROP_YIELD',axis=1)\n",
    "y=df['CROP_YIELD']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba41d41f",
   "metadata": {},
   "source": [
    "The 'train_test_split'  is to divide the dataset into training and testing sets. It separates the features ('X_train' and 'X_test') and the target variable ('y_train' and 'y_test') with a 20% test size, i have considered the 80% of training set as the total number of observations are less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dec84e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc7d35",
   "metadata": {},
   "source": [
    "### Step 4: Balancing the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c6e92f",
   "metadata": {},
   "source": [
    "Here we are balancing the dataset and we are using the RandomUnderSampler for attaining the goal, The random undersampler is used as the distribution of the classes are skewed as the data is looking biased,the randomunders sampler randomly deletes the  the majority class in the train set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c238c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler()\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "#adasyn = ADASYN()\n",
    "#smote = SMOTE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80180a40",
   "metadata": {},
   "source": [
    "Here we are Creating a data frame named performance to store the metrices that are required to evaluate the performance and efficieny of all the Models we are going to fit. We are using the fbeta_score to calculate the f2 score, where f2 score is calculated when we want to pioritize the recall rather than the precision as the minority class is quite smaller than the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4fad295",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": [], \"F2\": [], \"Parameters\": []})\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cab3de",
   "metadata": {},
   "source": [
    "Fitting the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5272f9d8",
   "metadata": {},
   "source": [
    "The Support Vector Machine(SVM) is more effective both in linear and non linear decision boundaries, where the svm always looks for a hyperplane that seperates the data points into different classes where the data points that are close to the hyperplane are the support vectors and the line that separates is the hyper plane.We do have three Kernels in the SVM, these kernels will help the SVM to handle the non linear classification without having to explicitly perform the data transformation which can be expensive computationally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ead4c6",
   "metadata": {},
   "source": [
    "We are implementing the Hyper parameter tuning where we find the optimal hyperparameters as we know that the paramters can impact the performace of the model. We are using the Grid search where we define the set of parameters and the we check the performance of the model by trying these combinations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331c1b00",
   "metadata": {},
   "source": [
    "### Step 5: Fitting the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a1abc5",
   "metadata": {},
   "source": [
    "#### Implementing Support Vector Machine with Linear as Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908addc0",
   "metadata": {},
   "source": [
    "We are consider the below C values, where C is the factor that controls the regularization strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f63d8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    }
   ],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C': [0.001,0.01, 0.1, 0.5, 1, 5, 10, 50, 100],  \n",
    "              'kernel': ['linear']}\n",
    "  \n",
    "#grid = GridSearchCV(SVC(), param_grid, scoring='f1', refit = True, verbose = 3, n_jobs=-1) \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, scoring=f2_scorer, refit = True, verbose = 3, n_jobs=-1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "_ = grid.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ab8d40",
   "metadata": {},
   "source": [
    "The total fits are 45 as we can see that 5 folds are being performed by testing the 9 different combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4db0d186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'kernel': 'linear'}\n",
      "SVC(C=0.001, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_)\n",
    "\n",
    "y_pred = grid.predict(X_test) \n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({\"model\": [\"SVM Linear\"], \"Accuracy\": [accuracy], \"Precision\": [precision], \"Recall\": [recall], \"F1\": [f1], \"F2\": [f2], \"Parameters\": [grid.best_params_]})])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0d0ab",
   "metadata": {},
   "source": [
    "Here we are capturng the best C value which is 0.1 for the kernel linear "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbac74f",
   "metadata": {},
   "source": [
    "Generating The Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b30730b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[122,  12],\n",
       "       [  9,  57]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM_L= confusion_matrix(y_test,y_pred)\n",
    "CM_L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28a339a",
   "metadata": {},
   "source": [
    "####  Implementing Support Vector Machine with rbf as Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d165ff",
   "metadata": {},
   "source": [
    "The radial basis function which uses the Gaussian radial basis function to transform the data points into high dimensional space without computing the transformed feature and the gama value controls the widdth of the Gaussian function where when it is small the decision boundaries are much more smoother and when it is large the detailing of the data will be more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a9dc4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf']}\n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, scoring=f2_scorer, refit = True, verbose = 3, n_jobs=-1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "_ = grid.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39efd461",
   "metadata": {},
   "source": [
    "The total fits are 100 as we can see that 5 folds are being performed by testing the 20 different combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6e02204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "SVC(C=10, gamma=0.01)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_)\n",
    "\n",
    "y_pred = grid.predict(X_test) \n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({\"model\": [\"SVM rbf\"], \"Accuracy\": [accuracy], \"Precision\": [precision], \"Recall\": [recall], \"F1\": [f1], \"F2\": [f2],\"Parameters\": [grid.best_params_]})])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a414672b",
   "metadata": {},
   "source": [
    "Here we are capturing the best C value which is 100 and the Gama value is 0.01 for the kernel rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b41a28",
   "metadata": {},
   "source": [
    "Generating The Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a22269df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[132,   2],\n",
       "       [  0,  66]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM_RBF= confusion_matrix(y_test,y_pred)\n",
    "CM_RBF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8146402f",
   "metadata": {},
   "source": [
    "###  Implementing Support Vector Machine with Poly as Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f913dd",
   "metadata": {},
   "source": [
    "The Coef0 will effect the flexibilty of the model so we are trying down a range of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81fe2c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    }
   ],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C': [0.01, 0.1, 0.5, 1, 5, 10, 50, 100],  \n",
    "              'coef0': [0.01, 0.1, 0.5, 1, 5, 10, 50, 100],\n",
    "              'kernel': ['poly']}\n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, scoring=f2_scorer, refit = True, verbose = 3, n_jobs=-1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "_ = grid.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d00595",
   "metadata": {},
   "source": [
    "The total fits are 320 as we can see that 5 folds are being performed by testing the 64 different combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f770743c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'coef0': 100, 'kernel': 'poly'}\n",
      "SVC(C=100, coef0=100, kernel='poly')\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_)\n",
    "\n",
    "y_pred = grid.predict(X_test) \n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "\n",
    "\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({\"model\": [\"SVM Poly\"], \"Accuracy\": [accuracy], \"Precision\": [precision], \"Recall\": [recall], \"F1\": [f1], \"F2\": [f2], \"Parameters\": [grid.best_params_]})])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231848b6",
   "metadata": {},
   "source": [
    "Here we are capturing the best C value which is 100 and the Coef value is 5 for the kernel Poly "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04bb61",
   "metadata": {},
   "source": [
    "Generating The Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e227bdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[132,   2],\n",
       "       [  2,  64]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM_P= confusion_matrix(y_test,y_pred)\n",
    "CM_P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc606dd4",
   "metadata": {},
   "source": [
    "We are printing the metrices of all the SVM models we have implemented "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2abfa594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Linear</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.855856</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM rbf</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Poly</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>{'C': 100, 'coef0': 100, 'kernel': 'poly'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  Accuracy  Precision    Recall        F1        F2  \\\n",
       "0  SVM Linear     0.895   0.826087  0.863636  0.844444  0.855856   \n",
       "0     SVM rbf     0.990   0.970588  1.000000  0.985075  0.993976   \n",
       "0    SVM Poly     0.980   0.969697  0.969697  0.969697  0.969697   \n",
       "\n",
       "                                   Parameters  \n",
       "0            {'C': 0.001, 'kernel': 'linear'}  \n",
       "0   {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}  \n",
       "0  {'C': 100, 'coef0': 100, 'kernel': 'poly'}  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2366eb3",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b99560",
   "metadata": {},
   "source": [
    "I have Genereated  a synthetic dataset with two inputs and one output where my inputs describes the  TEMPERATURES_DEVIATION\n",
    " and the SOIL_MOISTURE and the output is the CROP_YIELD which is dependednt on the input variables and done the preprocessing of the data and splitted the data by train test split method.The dataset looks imbalanced so i have used the RandomUndersampler technique to balnce the data set and fitted the  Support Vector Machine model by using hyper parameter tuning to test different combinations of parameters by using Grid search abnd got the below results.\n",
    " #### ACCURACY\n",
    "- The accuracy of the SVM model with Kernel as Linear is 0.895\n",
    "- The accuracy of the SVM model with Kernel as rbf is 0.985\n",
    "- The accuracy of the SVM model with Kernel as poly is 0.990\n",
    "\n",
    " #### Precision\n",
    "- The Precision of the SVM model with Kernel as Linear is 0.826087\n",
    "- The Precision of the SVM model with Kernel as rbf is 0.956522\t\n",
    "- The Precision of the SVM model with Kernel as poly is 0.970588\n",
    " \n",
    " #### Recall\n",
    "- The Recall of the SVM model with Kernel as Linear is 0.863636\n",
    "- The Recall of the SVM model with Kernel as rbf is 1.00\n",
    "- The Recall of the SVM model with Kernel as poly is 1.00\n",
    " \n",
    " #### F1 Score\n",
    "- The F1 Score of the SVM model with Kernel as Linear is 0.844444\t\n",
    "- The F1 Score of the SVM model with Kernel as rbf is 0.977778\n",
    "- The F1 Score of the SVM model with Kernel as poly is 0.993976\n",
    " \n",
    " #### F2 Score\n",
    "- The F2 Score of the SVM model with Kernel as Linear is 0.855856\t\n",
    "- The F2 Score of the SVM model with Kernel as rbf is 0.990991\n",
    "- The F2 Score of the SVM model with Kernel as poly is \t0.993976\n",
    "\n",
    "\n",
    "From the Performance dataframe we can observe that the C value is high for both the SVM kernel- rbf and the kernel- Poly\n",
    " where C is the regularization parameter that determines the width of the margin and the no of violations. \n",
    " In our case C is valued as 100 for both Kernels RBF and Poly that means the margin will be small  and the no of violations will be less which will be sign of overfitting and we can see that the boost in the accuracy from 0.895 when the kernel is Linear  to 0.985(Kernel- rbf) and 0.990(Kernel-Poly) and the recall is also equivalent to 1 for these both kernels(Poly,rbf) which can also be a sign of overfitting.However we should also consider the fact that the dataset is quite small.The SVM Linear model is the best model for predicting the target Crop_yield as the C value is minimum which is 0.1 which means the more regularization has been performed and the margin will be quite wider hyperplane seperating the classses.The decision boundary is also smoother which may generalize and prevents over fitting of the model.When we look at the confusion matrix of the SVM linear model the True Positives are 122 which means the model have predicted that there will be crop yield when there is actually crop yield and the True negatives are also 57 which means there is no crop yield then the model have predicted it truly and classified as Neative.We can cosider that the SVM Linear Kernel is better model for predicting the Crop Yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882bc053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
